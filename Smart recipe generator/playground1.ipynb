{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750c72a4-2974-43ef-b4d4-a473832e0783",
   "metadata": {},
   "source": [
    "# Homework - Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "656a5d1f-d419-4852-8b0c-f3c294e38308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "490bab2d-9e85-4c9f-9984-cc2c6b1d77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"AppetIte_Dataset.csv\"\n",
    "appetite_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11e974b9-6687-4500-a272-55f9ba56deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Dataset Information ===\n",
      "Total Records: 13501\n",
      "Total Features: 8\n",
      "\n",
      "Column Names:\n",
      "['recipe_id', 'recipe_name', 'ingredients', 'instructions', 'image_path', 'category', 'storage_tips', 'nutrition_score']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Basic Dataset Information ===\")\n",
    "print(f\"Total Records: {appetite_df.shape[0]}\")\n",
    "print(f\"Total Features: {appetite_df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(appetite_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf34ee2f-f5ba-402f-91e8-4742ef782963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types & Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13501 entries, 0 to 13500\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   recipe_id        13501 non-null  int64  \n",
      " 1   recipe_name      13501 non-null  int64  \n",
      " 2   ingredients      13501 non-null  object \n",
      " 3   instructions     13493 non-null  object \n",
      " 4   image_path       13501 non-null  object \n",
      " 5   category         13501 non-null  object \n",
      " 6   storage_tips     13501 non-null  object \n",
      " 7   nutrition_score  13501 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 843.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Types & Non-Null Counts:\")\n",
    "print(appetite_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd99eab2-7638-4670-a3da-46f22b759bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Statistics (for numeric columns) ===\n",
      "                   count unique  \\\n",
      "recipe_id        13501.0    NaN   \n",
      "recipe_name      13501.0    NaN   \n",
      "ingredients        13501  13473   \n",
      "instructions       13493  13464   \n",
      "image_path         13501  13472   \n",
      "category           13501      4   \n",
      "storage_tips       13501      1   \n",
      "nutrition_score  13501.0    NaN   \n",
      "\n",
      "                                                               top   freq  \\\n",
      "recipe_id                                                      NaN    NaN   \n",
      "recipe_name                                                    NaN    NaN   \n",
      "ingredients                                                     []     12   \n",
      "instructions     place ingredients in blender in the order list...      5   \n",
      "image_path                                                  #NAME?     30   \n",
      "category                                                 Indulgent  10685   \n",
      "storage_tips     Store ingredients in airtight containers; refr...  13501   \n",
      "nutrition_score                                                NaN    NaN   \n",
      "\n",
      "                     mean          std  min     25%     50%      75%      max  \n",
      "recipe_id          6751.0  3897.547327  1.0  3376.0  6751.0  10126.0  13501.0  \n",
      "recipe_name        6750.0  3897.547327  0.0  3375.0  6750.0  10125.0  13500.0  \n",
      "ingredients           NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "instructions          NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "image_path            NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "category              NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "storage_tips          NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "nutrition_score  0.775893     0.101012  0.6    0.69    0.78     0.86     0.95  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Summary Statistics (for numeric columns) ===\")\n",
    "print(appetite_df.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "219e4e4b-7278-417e-864f-10e9d5762e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Data (first 5 rows) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>image_path</th>\n",
       "      <th>category</th>\n",
       "      <th>storage_tips</th>\n",
       "      <th>nutrition_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n",
       "      <td>pat chicken dry with paper towels, season all ...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "      <td>preheat oven to 400°f and line a rimmed baking...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "      <td>place a rack in middle of oven; preheat to 400...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>['1 (¾- to 1-pound) round italian loaf, cut in...</td>\n",
       "      <td>preheat oven to 350°f with rack in middle. gen...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "      <td>stir together brown sugar and hot water in a c...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>Quick Meals</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  recipe_name                                        ingredients  \\\n",
       "0          1            0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
       "1          2            1  ['2 large egg whites', '1 pound new potatoes (...   \n",
       "2          3            2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
       "3          4            3  ['1 (¾- to 1-pound) round italian loaf, cut in...   \n",
       "4          5            4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  pat chicken dry with paper towels, season all ...   \n",
       "1  preheat oven to 400°f and line a rimmed baking...   \n",
       "2  place a rack in middle of oven; preheat to 400...   \n",
       "3  preheat oven to 350°f with rack in middle. gen...   \n",
       "4  stir together brown sugar and hot water in a c...   \n",
       "\n",
       "                                          image_path     category  \\\n",
       "0  miso-butter-roast-chicken-acorn-squash-panzanella    Indulgent   \n",
       "1         crispy-salt-and-pepper-potatoes-dan-kluger    Indulgent   \n",
       "2         thanksgiving-mac-and-cheese-erick-williams    Indulgent   \n",
       "3          italian-sausage-and-bread-stuffing-240559      Healthy   \n",
       "4                 newtons-law-apple-bourbon-cocktail  Quick Meals   \n",
       "\n",
       "                                        storage_tips  nutrition_score  \n",
       "0  Store ingredients in airtight containers; refr...             0.63  \n",
       "1  Store ingredients in airtight containers; refr...             0.83  \n",
       "2  Store ingredients in airtight containers; refr...             0.68  \n",
       "3  Store ingredients in airtight containers; refr...             0.69  \n",
       "4  Store ingredients in airtight containers; refr...             0.65  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n=== Sample Data (first 5 rows) ===\")\n",
    "display(appetite_df.head())\n",
    "curated_path = \"data/curated/AppetIte_Dataset_v1.csv\"\n",
    "os.makedirs(\"data/curated\", exist_ok=True)\n",
    "appetite_df.to_csv(curated_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4b8da-e76c-40fd-b4da-fbe5180b94c5",
   "metadata": {},
   "source": [
    "# Homework - Model development (The very first steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86877c0-b2b7-4ce9-87ce-04f2837cff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "150cfddc-f80c-459d-ae8a-63c94fa7977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3cb962f-7513-4a99-9096-8cee1410ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef1b9c7-1b14-49f6-84b6-f8526bcb7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'facebook/bart-large-cnn' loaded successfully on device: mps\n",
      "Number of parameters: 406,290,432\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model '{model_name}' loaded successfully on device: {device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02351f8d-2902-4296-9bf6-e3dca3ca62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = [\n",
    "    \"ingredients: chicken, rice, soy sauce, garlic, egg\",\n",
    "    \"ingredients: spinach, tomato, feta cheese, olive oil\",\n",
    "    \"ingredients: oats, honey, banana, milk\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129cf67-f3db-49cf-99d8-f4686c4602c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: ingredients: chicken, rice, soy sauce, garlic, egg\n",
      " Generated Recipe Suggestion: ingredients: chicken, rice, soy sauce, garlic, egg, egg and rice. Serves 8 people at a time\n",
      "\n",
      "Input: ingredients: spinach, tomato, feta cheese, olive oil\n",
      " Generated Recipe Suggestion: ingredients: spinach, tomato, feta cheese, olive oil and olive oil. Serves 2-3 people at a\n",
      "\n",
      "Input: ingredients: oats, honey, banana, milk\n",
      " Generated Recipe Suggestion: ingredients: oats, honey, banana, milk, milk. Serves 4 people. For more information, visit www.\n"
     ]
    }
   ],
   "source": [
    "for text in sample_inputs:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=30,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(f\" Generated Recipe Suggestion: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bddaf39-7258-42c5-a3c5-a5b0ea221ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Embedding shape: (1, 1024)\n",
      "These embeddings can be used for clustering or category classifiers (Healthy, Quick, etc.).\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sample_inputs[0], return_tensors=\"pt\").to(device)\n",
    "    outputs = model.model.encoder(**inputs, output_hidden_states=True)\n",
    "    # Grab last hidden state\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "print(\"\\n Embedding shape:\", embeddings.shape)\n",
    "print(\"These embeddings can be used for clustering or category classifiers (Healthy, Quick, etc.).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31591fc0-e80c-4ceb-a0dd-d6e70f506ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Example Generated Output:\n",
      "ingredients: pasta, tomato, garlic, olive oil, basil, basil. Serves 4-6 people. For more information, go to www.gofundme.com/sauceof pasta. For\n"
     ]
    }
   ],
   "source": [
    "test_input = \"ingredients: pasta, tomato, garlic, olive oil, basil\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(**inputs, max_length=50, num_beams=4, early_stopping=True)\n",
    "recipe_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n Example Generated Output:\")\n",
    "print(recipe_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c854e9c-daea-4819-b37a-ba56f07ce823",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "- Fine-tune on curated AppetIte_Dataset.csv (input_text → target_text)\n",
    "- Evaluate recipe coherence & category alignment\n",
    "- Optionally distill or prune model for lower latency (<2 s goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf0bd0",
   "metadata": {},
   "source": [
    "# Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4207203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Training samples: 2,000\n",
      "Validation samples: 500\n",
      "Training started\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084ac857d7c5421db8613a82b1f62192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d27f0ccbb64d1bb2761620d67530a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17.9904\n",
      "Validation Loss: 20.9060\n",
      "Epoch Duration: 8.07 minutes\n",
      "New best model - saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c8353984c24e20a9cb060b41dbbb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff62ddcb21441679362df9fb80d180b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 22.0239\n",
      "Validation Loss: 22.2065\n",
      "Epoch Duration: 7.84 minutes\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "df = pd.read_csv(\"data/curated/AppetIte_Dataset_v1.csv\")\n",
    "\n",
    "def prepare_input_text(row):\n",
    "    ingredients = row['ingredients'] if pd.notna(row['ingredients']) else 'no ingredients listed'\n",
    "    category = row['category'] if pd.notna(row['category']) else 'general'\n",
    "    return f\"Generate a {category} recipe using: {ingredients}\"\n",
    "\n",
    "def prepare_target_text(row):\n",
    "    recipe_name = row['recipe_name'] if pd.notna(row['recipe_name']) else 'Delicious Recipe'\n",
    "    instructions = row['instructions'] if pd.notna(row['instructions']) else 'Instructions not available'\n",
    "    return f\"Recipe: {recipe_name}. Instructions: {instructions}\"\n",
    "\n",
    "df['input_text'] = df.apply(prepare_input_text, axis=1)\n",
    "df['target_text'] = df.apply(prepare_target_text, axis=1)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['category'])\n",
    "\n",
    "train_df = train_df.head(2000).reset_index(drop=True)\n",
    "val_df = val_df.head(500).reset_index(drop=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")\n",
    "\n",
    "model_name = \"facebook/bart-base\"  # faster than large-cnn\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_length=128, max_target_length=256):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.data.loc[idx, 'input_text']\n",
    "        target_text = self.data.loc[idx, 'target_text']\n",
    "        \n",
    "        input_encoding = self.tokenizer(input_text,\n",
    "                                        max_length=self.max_input_length,\n",
    "                                        padding=\"max_length\",\n",
    "                                        truncation=True,\n",
    "                                        return_tensors=\"pt\")\n",
    "        target_encoding = self.tokenizer(target_text,\n",
    "                                         max_length=self.max_target_length,\n",
    "                                         padding=\"max_length\",\n",
    "                                         truncation=True,\n",
    "                                         return_tensors=\"pt\")\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "                'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "                'labels': labels}\n",
    "\n",
    "train_dataset = RecipeDataset(train_df, tokenizer)\n",
    "val_dataset = RecipeDataset(val_df, tokenizer)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 8\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = (len(train_loader) // GRADIENT_ACCUMULATION_STEPS) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}'})\n",
    "    if hasattr(torch, 'mps') and torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            progress_bar.set_postfix({'Val Loss': f'{outputs.loss.item():.4f}'})\n",
    "            if batch_idx % 10 == 0 and hasattr(torch, 'mps') and torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"training_logs\", exist_ok=True)\n",
    "\n",
    "print(f\"Training started\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "training_history = {'train_loss': [], 'val_loss': [], 'epoch_times': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    \n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    epoch_time = time.time() - start_time\n",
    "    training_history['epoch_times'].append(epoch_time)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Epoch Duration: {epoch_time/60:.2f} minutes\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(\"New best model - saving...\")\n",
    "        model.save_pretrained(\"models/appetite_bart_best\")\n",
    "        tokenizer.save_pretrained(\"models/appetite_bart_best\")\n",
    "        model_info = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'training_time': sum(training_history['epoch_times']),\n",
    "            'date_saved': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        with open('models/appetite_bart_best/training_info.json', 'w') as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "\n",
    "with open('training_logs/training_history.json', 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471ee0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model loaded\n",
      "Best epoch: 1\n",
      "Validation loss: 20.9060\n",
      "Training time: 8.1 minutes\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "finetuned_model = BartForConditionalGeneration.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_tokenizer = BartTokenizer.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "print(\"Fine-tuned model loaded\")\n",
    "\n",
    "try:\n",
    "    with open('models/appetite_bart_best/training_info.json', 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    print(f\"Best epoch: {training_info['epoch']}\")\n",
    "    print(f\"Validation loss: {training_info['val_loss']:.4f}\")\n",
    "    print(f\"Training time: {training_info['training_time']/60:.1f} minutes\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648c94ca-8589-4e84-9e22-f2922999090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ALLERGENS = ['peanut', 'milk', 'egg', 'soy', 'fish', 'shellfish', 'wheat', 'gluten', 'sesame']\n",
    "\n",
    "def detect_allergens(text):\n",
    "    found = [a for a in ALLERGENS if re.search(rf'\\\\b{a}\\\\b', text.lower())]\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4417595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fine-tuned model:\n",
      "\n",
      "Test 1\n",
      "Input: Generate a Healthy recipe using: ['chicken breast', 'broccoli', 'olive oil', 'garlic', 'lemon']\n",
      "Test 2\n",
      "Input: Generate a Quick Meals recipe using: ['pasta', 'tomato sauce', 'basil', 'mozzarella cheese']\n",
      "Test 3\n",
      "Input: Generate an Indulgent recipe using: ['chocolate', 'cream', 'butter', 'vanilla', 'eggs']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "finetuned_model = BartForConditionalGeneration.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_tokenizer = BartTokenizer.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "finetuned_model.eval()\n",
    "\n",
    "test_recipes = [\n",
    "    \"Generate a Healthy recipe using: ['chicken breast', 'broccoli', 'olive oil', 'garlic', 'lemon']\",\n",
    "    \"Generate a Quick Meals recipe using: ['pasta', 'tomato sauce', 'basil', 'mozzarella cheese']\",\n",
    "    \"Generate an Indulgent recipe using: ['chocolate', 'cream', 'butter', 'vanilla', 'eggs']\"\n",
    "]\n",
    "\n",
    "print(\"Testing fine-tuned model:\\n\")\n",
    "\n",
    "for i, test_input in enumerate(test_recipes, 1):\n",
    "    print(f\"Test {i}\")\n",
    "    print(f\"Input: {test_input}\")\n",
    "    \n",
    "    inputs = finetuned_tokenizer(test_input, return_tensors=\"pt\", max_length=128, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = finetuned_model.generate(\n",
    "            **inputs,\n",
    "            max_length=150,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=3,\n",
    "            early_stopping=True,\n",
    "            temperature=0.8,\n",
    "            do_sample=True\n",
    "            )\n",
    "    ai_recipe = finetuned_tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2917b6a8-bc47-416d-b6c0-230865e25ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 50 samples...\n",
      "\n",
      "Evaluation Results:\n",
      "ROUGE-1: 0.0000\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0000\n",
      "\n",
      "Overall ROUGE: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from rouge_score import rouge_scorer\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', 'rouge-score'], check=True)\n",
    "    from rouge_score import rouge_scorer\n",
    "\n",
    "def simple_evaluation(model, tokenizer, val_df, device, num_samples=50):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    model.eval()\n",
    "    sample_indices = np.random.choice(len(val_df), min(num_samples, len(val_df)), replace=False)\n",
    "    \n",
    "    print(f\"Evaluating on {len(sample_indices)} samples...\")\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        input_text = val_df.iloc[idx]['input_text']\n",
    "        reference_text = val_df.iloc[idx]['target_text']\n",
    "        \n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=128, truncation=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_length=150, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        try:\n",
    "            scores = scorer.score(reference_text, prediction)\n",
    "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    results = {\n",
    "        'ROUGE-1': np.mean(rouge1_scores),\n",
    "        'ROUGE-2': np.mean(rouge2_scores),\n",
    "        'ROUGE-L': np.mean(rougeL_scores)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "eval_results = simple_evaluation(finetuned_model, finetuned_tokenizer, val_df, device, num_samples=50)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"ROUGE-1: {eval_results['ROUGE-1']:.4f}\")\n",
    "print(f\"ROUGE-2: {eval_results['ROUGE-2']:.4f}\")\n",
    "print(f\"ROUGE-L: {eval_results['ROUGE-L']:.4f}\")\n",
    "\n",
    "overall_rouge = (eval_results['ROUGE-1'] + eval_results['ROUGE-2'] + eval_results['ROUGE-L']) / 3\n",
    "print(f\"\\nOverall ROUGE: {overall_rouge:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f951c",
   "metadata": {},
   "source": [
    "# Model Development Complete\n",
    "\n",
    "## Completed Steps\n",
    "\n",
    "- Data preparation with train/validation split\n",
    "- PyTorch dataset implementation\n",
    "- Model fine-tuning with progress tracking\n",
    "- Training visualization\n",
    "- Model testing on diverse examples\n",
    "- Comprehensive ROUGE evaluation\n",
    "- Safety checks and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd175f33-96b1-471e-8eda-7a6561df8582",
   "metadata": {},
   "source": [
    "# Risk Management and Trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f07f2aff-7ae0-4084-89dd-b8e71ce9cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def check_dataset_quality(df):\n",
    "    print(\"Data Quality Check\")\n",
    "    print(\"Rows:\", len(df), \", Columns:\", len(df.columns))\n",
    "    print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "    print(\"Duplicate Rows:\", df.duplicated().sum())\n",
    "    \n",
    "    category_col = None\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'category':\n",
    "            category_col = col\n",
    "            break\n",
    "    \n",
    "    if category_col:\n",
    "        print(\"Category Distribution:\\n\", df[category_col].value_counts())\n",
    "    else:\n",
    "        print(\"No 'category' column found in dataset.\")\n",
    "    \n",
    "    print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcb9a6-489a-4028-880f-2586094e53d9",
   "metadata": {},
   "source": [
    "**Safety & Allergen Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a156d6a-c6e6-4723-80ee-a049a1b6692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLERGENS = ['peanut', 'milk', 'egg', 'soy', 'fish', 'shellfish', 'wheat', 'gluten', 'sesame']\n",
    "\n",
    "def detect_allergens(text):\n",
    "    found = [a for a in ALLERGENS if re.search(rf'\\b{a}\\b', str(text).lower())]\n",
    "    return found\n",
    "\n",
    "def safety_check(recipe_text):\n",
    "    if detect_allergens(recipe_text):\n",
    "        print(f\"Warning: Contains allergens: {detect_allergens(recipe_text)}\")\n",
    "    if any(bad in recipe_text.lower() for bad in ['kill', 'poison', 'suicide']):\n",
    "        print(\"Unsafe content detected! Review required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a743e4-134c-43f5-8731-e94dd3179828",
   "metadata": {},
   "source": [
    "**Simple Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6d45306-30fb-4982-825b-15e803fdad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prediction(input_text, output_text):\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"input\": input_text,\n",
    "        \"output\": output_text\n",
    "    }\n",
    "    with open(\"logs/predictions.jsonl\", \"a\") as f:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "    print(\" Logged prediction for monitoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed32f56-23ab-4f9b-8304-a89b30c51247",
   "metadata": {},
   "source": [
    "**Trustworthy Model Card Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08bf50fd-ca0d-4a29-bdfa-4dd6e4bfcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_card(name=\"AppetIte-BART\", version=\"v1.0\"):\n",
    "    card = f\"\"\"\n",
    "# Model Card: {name}\n",
    "**Version:** {version}\n",
    "**Purpose:** Generate recipes from ingredients.\n",
    "**Training Data:** Curated AppetIte_Dataset.csv\n",
    "**Risks:** May include allergen ingredients or biased cuisine categories.\n",
    "**Mitigations:** Allergen filter, user feedback, manual review.\n",
    "**Contact:** Sharath / Project Maintainer\n",
    "\"\"\"\n",
    "    with open(\"MODEL_CARD.md\", \"w\") as f:\n",
    "        f.write(card)\n",
    "    print(\" Model Card created (MODEL_CARD.md)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affee609-a171-43eb-9952-e16d234dfa27",
   "metadata": {},
   "source": [
    "**Example Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "820e549d-9188-406c-a444-519f7f0a1018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Check\n",
      "Rows: 13501 , Columns: 8\n",
      "Missing Values:\n",
      " recipe_id          0\n",
      "recipe_name        0\n",
      "ingredients        0\n",
      "instructions       8\n",
      "image_path         0\n",
      "category           0\n",
      "storage_tips       0\n",
      "nutrition_score    0\n",
      "dtype: int64\n",
      "Duplicate Rows: 0\n",
      "Category Distribution:\n",
      " category\n",
      "Indulgent          10685\n",
      "Healthy             1437\n",
      "Quick Meals         1308\n",
      "Family-Friendly       71\n",
      "Name: count, dtype: int64\n",
      "==========================\n",
      "Warning: Contains allergens: ['peanut']\n",
      " Logged prediction for monitoring.\n",
      " Model Card created (MODEL_CARD.md)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/nw2d4nm51zj7xgfrvxnrzz440000gn/T/ipykernel_2543/1022548407.py:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/curated/AppetIte_Dataset_v1.csv\")\n",
    "\n",
    "check_dataset_quality(df)\n",
    "\n",
    "sample_input = \"ingredients: peanut butter, banana, honey\"\n",
    "sample_output = \"peanut butter banana smoothie\"\n",
    "\n",
    "safety_check(sample_output)\n",
    "\n",
    "log_prediction(sample_input, sample_output)\n",
    "\n",
    "create_model_card()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
