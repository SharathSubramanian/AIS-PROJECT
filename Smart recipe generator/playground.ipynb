{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750c72a4-2974-43ef-b4d4-a473832e0783",
   "metadata": {},
   "source": [
    "# Homework - Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656a5d1f-d419-4852-8b0c-f3c294e38308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490bab2d-9e85-4c9f-9984-cc2c6b1d77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"AppetIte_Dataset.csv\"\n",
    "appetite_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e974b9-6687-4500-a272-55f9ba56deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Dataset Information ===\n",
      "Total Records: 13501\n",
      "Total Features: 8\n",
      "\n",
      "Column Names:\n",
      "['recipe_id', 'recipe_name', 'ingredients', 'instructions', 'image_path', 'category', 'storage_tips', 'nutrition_score']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Basic Dataset Information ===\")\n",
    "print(f\"Total Records: {appetite_df.shape[0]}\")\n",
    "print(f\"Total Features: {appetite_df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(appetite_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf34ee2f-f5ba-402f-91e8-4742ef782963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Data Types & Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13501 entries, 0 to 13500\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   recipe_id        13501 non-null  int64  \n",
      " 1   recipe_name      13501 non-null  int64  \n",
      " 2   ingredients      13501 non-null  object \n",
      " 3   instructions     13493 non-null  object \n",
      " 4   image_path       13501 non-null  object \n",
      " 5   category         13501 non-null  object \n",
      " 6   storage_tips     13501 non-null  object \n",
      " 7   nutrition_score  13501 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 843.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Data Types & Non-Null Counts:\")\n",
    "print(appetite_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd99eab2-7638-4670-a3da-46f22b759bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Statistics (for numeric columns) ===\n",
      "                   count unique  \\\n",
      "recipe_id        13501.0    NaN   \n",
      "recipe_name      13501.0    NaN   \n",
      "ingredients        13501  13473   \n",
      "instructions       13493  13464   \n",
      "image_path         13501  13472   \n",
      "category           13501      4   \n",
      "storage_tips       13501      1   \n",
      "nutrition_score  13501.0    NaN   \n",
      "\n",
      "                                                               top   freq  \\\n",
      "recipe_id                                                      NaN    NaN   \n",
      "recipe_name                                                    NaN    NaN   \n",
      "ingredients                                                     []     12   \n",
      "instructions     place ingredients in blender in the order list...      5   \n",
      "image_path                                                  #NAME?     30   \n",
      "category                                                 Indulgent  10685   \n",
      "storage_tips     Store ingredients in airtight containers; refr...  13501   \n",
      "nutrition_score                                                NaN    NaN   \n",
      "\n",
      "                     mean          std  min     25%     50%      75%      max  \n",
      "recipe_id          6751.0  3897.547327  1.0  3376.0  6751.0  10126.0  13501.0  \n",
      "recipe_name        6750.0  3897.547327  0.0  3375.0  6750.0  10125.0  13500.0  \n",
      "ingredients           NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "instructions          NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "image_path            NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "category              NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "storage_tips          NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "nutrition_score  0.775893     0.101012  0.6    0.69    0.78     0.86     0.95  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Summary Statistics (for numeric columns) ===\")\n",
    "print(appetite_df.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219e4e4b-7278-417e-864f-10e9d5762e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Data (first 5 rows) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>image_path</th>\n",
       "      <th>category</th>\n",
       "      <th>storage_tips</th>\n",
       "      <th>nutrition_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['1 (3¬Ω‚Äì4-lb.) whole chicken', '2¬æ tsp. kosher...</td>\n",
       "      <td>pat chicken dry with paper towels, season all ...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "      <td>preheat oven to 400¬∞f and line a rimmed baking...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "      <td>place a rack in middle of oven; preheat to 400...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>['1 (¬æ- to 1-pound) round italian loaf, cut in...</td>\n",
       "      <td>preheat oven to 350¬∞f with rack in middle. gen...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "      <td>stir together brown sugar and hot water in a c...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>Quick Meals</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  recipe_name                                        ingredients  \\\n",
       "0          1            0  ['1 (3¬Ω‚Äì4-lb.) whole chicken', '2¬æ tsp. kosher...   \n",
       "1          2            1  ['2 large egg whites', '1 pound new potatoes (...   \n",
       "2          3            2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
       "3          4            3  ['1 (¬æ- to 1-pound) round italian loaf, cut in...   \n",
       "4          5            4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  pat chicken dry with paper towels, season all ...   \n",
       "1  preheat oven to 400¬∞f and line a rimmed baking...   \n",
       "2  place a rack in middle of oven; preheat to 400...   \n",
       "3  preheat oven to 350¬∞f with rack in middle. gen...   \n",
       "4  stir together brown sugar and hot water in a c...   \n",
       "\n",
       "                                          image_path     category  \\\n",
       "0  miso-butter-roast-chicken-acorn-squash-panzanella    Indulgent   \n",
       "1         crispy-salt-and-pepper-potatoes-dan-kluger    Indulgent   \n",
       "2         thanksgiving-mac-and-cheese-erick-williams    Indulgent   \n",
       "3          italian-sausage-and-bread-stuffing-240559      Healthy   \n",
       "4                 newtons-law-apple-bourbon-cocktail  Quick Meals   \n",
       "\n",
       "                                        storage_tips  nutrition_score  \n",
       "0  Store ingredients in airtight containers; refr...             0.63  \n",
       "1  Store ingredients in airtight containers; refr...             0.83  \n",
       "2  Store ingredients in airtight containers; refr...             0.68  \n",
       "3  Store ingredients in airtight containers; refr...             0.69  \n",
       "4  Store ingredients in airtight containers; refr...             0.65  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n=== Sample Data (first 5 rows) ===\")\n",
    "display(appetite_df.head())\n",
    "curated_path = \"data/curated/AppetIte_Dataset_v1.csv\"\n",
    "os.makedirs(\"data/curated\", exist_ok=True)\n",
    "appetite_df.to_csv(curated_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4b8da-e76c-40fd-b4da-fbe5180b94c5",
   "metadata": {},
   "source": [
    "# Homework - Model development (The very first steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86877c0-b2b7-4ce9-87ce-04f2837cff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150cfddc-f80c-459d-ae8a-63c94fa7977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3cb962f-7513-4a99-9096-8cee1410ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef1b9c7-1b14-49f6-84b6-f8526bcb7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'facebook/bart-large-cnn' loaded successfully on device: mps\n",
      "Number of parameters: 406,290,432\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model '{model_name}' loaded successfully on device: {device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02351f8d-2902-4296-9bf6-e3dca3ca62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = [\n",
    "    \"ingredients: chicken, rice, soy sauce, garlic, egg\",\n",
    "    \"ingredients: spinach, tomato, feta cheese, olive oil\",\n",
    "    \"ingredients: oats, honey, banana, milk\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129cf67-f3db-49cf-99d8-f4686c4602c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Input: ingredients: chicken, rice, soy sauce, garlic, egg\n",
      " Generated Recipe Suggestion: ingredients: chicken, rice, soy sauce, garlic, egg, egg and rice. Serves 8 people at a time\n",
      "\n",
      "üßæ Input: ingredients: spinach, tomato, feta cheese, olive oil\n",
      " Generated Recipe Suggestion: ingredients: spinach, tomato, feta cheese, olive oil and olive oil. Serves 2-3 people at a\n",
      "\n",
      "üßæ Input: ingredients: oats, honey, banana, milk\n",
      " Generated Recipe Suggestion: ingredients: oats, honey, banana, milk, milk. Serves 4 people. For more information, visit www.\n"
     ]
    }
   ],
   "source": [
    "for text in sample_inputs:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=30,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    print(f\"\\nüßæ Input: {text}\")\n",
    "    print(f\" Generated Recipe Suggestion: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bddaf39-7258-42c5-a3c5-a5b0ea221ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Embedding shape: (1, 1024)\n",
      "These embeddings can be used for clustering or category classifiers (Healthy, Quick, etc.).\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sample_inputs[0], return_tensors=\"pt\").to(device)\n",
    "    outputs = model.model.encoder(**inputs, output_hidden_states=True)\n",
    "    # Grab last hidden state\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "print(\"\\n Embedding shape:\", embeddings.shape)\n",
    "print(\"These embeddings can be used for clustering or category classifiers (Healthy, Quick, etc.).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31591fc0-e80c-4ceb-a0dd-d6e70f506ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Example Generated Output:\n",
      "ingredients: pasta, tomato, garlic, olive oil, basil, basil. Serves 4-6 people. For more information, go to www.gofundme.com/sauceof pasta. For\n"
     ]
    }
   ],
   "source": [
    "test_input = \"ingredients: pasta, tomato, garlic, olive oil, basil\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(**inputs, max_length=50, num_beams=4, early_stopping=True)\n",
    "recipe_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n Example Generated Output:\")\n",
    "print(recipe_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c854e9c-daea-4819-b37a-ba56f07ce823",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "- Fine-tune on curated AppetIte_Dataset.csv (input_text ‚Üí target_text)\n",
    "- Evaluate recipe coherence & category alignment\n",
    "- Optionally distill or prune model for lower latency (<2 s goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395cb16",
   "metadata": {},
   "source": [
    "# Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f364666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 11,475\n",
      "Validation samples: 2,026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/curated/AppetIte_Dataset_v1.csv\")\n",
    "\n",
    "def prepare_input_text(row):\n",
    "    ingredients = row['ingredients'] if pd.notna(row['ingredients']) else 'no ingredients listed'\n",
    "    category = row['category'] if pd.notna(row['category']) else 'general'\n",
    "    return f\"Generate a {category} recipe using: {ingredients}\"\n",
    "\n",
    "def prepare_target_text(row):\n",
    "    recipe_name = row['recipe_name'] if pd.notna(row['recipe_name']) else 'Delicious Recipe'\n",
    "    instructions = row['instructions'] if pd.notna(row['instructions']) else 'Instructions not available'\n",
    "    return f\"Recipe: {recipe_name}. Instructions: {instructions}\"\n",
    "\n",
    "df['input_text'] = df.apply(prepare_input_text, axis=1)\n",
    "df['target_text'] = df.apply(prepare_target_text, axis=1)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['category'])\n",
    "\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79601601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 11,475 examples\n",
      "Validation dataset: 2,026 examples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_length=256, max_target_length=512):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.data.loc[idx, 'input_text']\n",
    "        target_text = self.data.loc[idx, 'target_text']\n",
    "        \n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        labels = target_encoding['input_ids'].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "train_dataset = RecipeDataset(train_df, tokenizer)\n",
    "val_dataset = RecipeDataset(val_df, tokenizer)\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset):,} examples\")\n",
    "print(f\"Validation dataset: {len(val_dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d33489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4\n",
      "Epochs: 3\n",
      "Learning rate: 3e-05\n",
      "Total steps: 4,303\n",
      "Batches per epoch: 2,869\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_STEPS = 100\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * EPOCHS // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Total steps: {total_steps:,}\")\n",
    "print(f\"Batches per epoch: {len(train_loader):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13049e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            progress_bar.set_postfix({'Val Loss': f'{outputs.loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da92e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started: 2025-11-02 14:54:26\n",
      "Training on 11,475 recipes\n",
      "Validating on 2,026 recipes\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2986995e8342d3864df76d39257c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/2869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"training_logs\", exist_ok=True)\n",
    "\n",
    "print(f\"Training started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Training on {len(train_dataset):,} recipes\")\n",
    "print(f\"Validating on {len(val_dataset):,} recipes\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "training_history = {'train_loss': [], 'val_loss': [], 'epoch_times': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    \n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    training_history['epoch_times'].append(epoch_time)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Time: {epoch_time/60:.1f} minutes\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"New best model, saving...\")\n",
    "        \n",
    "        model.save_pretrained(\"models/appetite_bart_best\")\n",
    "        tokenizer.save_pretrained(\"models/appetite_bart_best\")\n",
    "        \n",
    "        model_info = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'training_time': sum(training_history['epoch_times']),\n",
    "            'date_saved': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open('models/appetite_bart_best/training_info.json', 'w') as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(f\"\\nTraining complete\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "with open('training_logs/training_history.json', 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(1, EPOCHS + 1)\n",
    "plt.plot(epochs_range, training_history['train_loss'], 'o-', label='Training Loss', linewidth=2)\n",
    "plt.plot(epochs_range, training_history['val_loss'], 's-', label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "epoch_times_minutes = [t/60 for t in training_history['epoch_times']]\n",
    "plt.bar(epochs_range, epoch_times_minutes, alpha=0.7, color='coral')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Time (minutes)')\n",
    "plt.title('Training Time per Epoch')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_progress.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "finetuned_model = BartForConditionalGeneration.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_tokenizer = BartTokenizer.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "print(\"Fine-tuned model loaded\")\n",
    "\n",
    "try:\n",
    "    with open('models/appetite_bart_best/training_info.json', 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    print(f\"Best epoch: {training_info['epoch']}\")\n",
    "    print(f\"Validation loss: {training_info['val_loss']:.4f}\")\n",
    "    print(f\"Training time: {training_info['training_time']/60:.1f} minutes\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recipes = [\n",
    "    \"Generate a Healthy recipe using: ['chicken breast', 'broccoli', 'olive oil', 'garlic', 'lemon', 'quinoa']\",\n",
    "    \"Generate a Quick Meals recipe using: ['pasta', 'tomato sauce', 'basil', 'mozzarella cheese', 'garlic']\",\n",
    "    \"Generate an Indulgent recipe using: ['dark chocolate', 'heavy cream', 'butter', 'vanilla extract', 'eggs']\"\n",
    "]\n",
    "\n",
    "finetuned_model.eval()\n",
    "\n",
    "for i, test_input in enumerate(test_recipes, 1):\n",
    "    print(f\"\\nTest {i}\")\n",
    "    \n",
    "    inputs = finetuned_tokenizer(test_input, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        generated_ids = finetuned_model.generate(\n",
    "            **inputs,\n",
    "            max_length=250,\n",
    "            num_beams=5,\n",
    "            temperature=0.8,\n",
    "            do_sample=True,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    ai_recipe = finetuned_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Generated Recipe: {ai_recipe}\")\n",
    "    print(f\"Generation time: {generation_time:.2f}s\")\n",
    "    print(f\"Length: {len(ai_recipe)} characters\")\n",
    "    \n",
    "    allergens = detect_allergens(ai_recipe)\n",
    "    if allergens:\n",
    "        print(f\"Allergens: {', '.join(allergens)}\")\n",
    "    \n",
    "    log_prediction(test_input, ai_recipe)\n",
    "\n",
    "print(\"\\nTesting complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from rouge_score import rouge_scorer\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', 'rouge-score'], check=True)\n",
    "    from rouge_score import rouge_scorer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, tokenizer, val_df, device, num_samples=100):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    generation_times = []\n",
    "    output_lengths = []\n",
    "    \n",
    "    model.eval()\n",
    "    sample_indices = np.random.choice(len(val_df), min(num_samples, len(val_df)), replace=False)\n",
    "    \n",
    "    for idx_num, idx in enumerate(sample_indices, 1):\n",
    "        if idx_num % 20 == 0:\n",
    "            print(f\"Progress: {idx_num}/{len(sample_indices)}\")\n",
    "        \n",
    "        input_text = val_df.iloc[idx]['input_text']\n",
    "        reference_text = val_df.iloc[idx]['target_text']\n",
    "        \n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_length=250, num_beams=4, early_stopping=True)\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        try:\n",
    "            scores = scorer.score(reference_text, prediction)\n",
    "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        except:\n",
    "            rouge1_scores.append(0.0)\n",
    "            rouge2_scores.append(0.0)\n",
    "            rougeL_scores.append(0.0)\n",
    "        \n",
    "        generation_times.append(generation_time)\n",
    "        output_lengths.append(len(prediction))\n",
    "    \n",
    "    results = {\n",
    "        'rouge1_mean': np.mean(rouge1_scores),\n",
    "        'rouge1_std': np.std(rouge1_scores),\n",
    "        'rouge2_mean': np.mean(rouge2_scores),\n",
    "        'rouge2_std': np.std(rouge2_scores),\n",
    "        'rougeL_mean': np.mean(rougeL_scores),\n",
    "        'rougeL_std': np.std(rougeL_scores),\n",
    "        'avg_generation_time': np.mean(generation_times),\n",
    "        'avg_output_length': np.mean(output_lengths),\n",
    "        'samples_evaluated': len(sample_indices)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Starting evaluation\")\n",
    "eval_results = evaluate_model(finetuned_model, finetuned_tokenizer, val_df, device, num_samples=min(100, len(val_df)))\n",
    "\n",
    "print(\"\\nEvaluation Results\")\n",
    "print(f\"ROUGE-1: {eval_results['rouge1_mean']:.4f} ¬± {eval_results['rouge1_std']:.4f}\")\n",
    "print(f\"ROUGE-2: {eval_results['rouge2_mean']:.4f} ¬± {eval_results['rouge2_std']:.4f}\")\n",
    "print(f\"ROUGE-L: {eval_results['rougeL_mean']:.4f} ¬± {eval_results['rougeL_std']:.4f}\")\n",
    "print(f\"Avg generation time: {eval_results['avg_generation_time']:.3f}s\")\n",
    "print(f\"Avg output length: {eval_results['avg_output_length']:.0f} characters\")\n",
    "print(f\"Samples evaluated: {eval_results['samples_evaluated']}\")\n",
    "\n",
    "overall_rouge = (eval_results['rouge1_mean'] + eval_results['rouge2_mean'] + eval_results['rougeL_mean']) / 3\n",
    "print(f\"Overall ROUGE: {overall_rouge:.4f}\")\n",
    "\n",
    "os.makedirs('evaluation_results', exist_ok=True)\n",
    "with open('evaluation_results/comprehensive_evaluation.json', 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "\n",
    "print(\"Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dae3eb",
   "metadata": {},
   "source": [
    "# Model Development Complete\n",
    "\n",
    "## Completed Steps\n",
    "\n",
    "- Data preparation with train/validation split\n",
    "- PyTorch dataset implementation\n",
    "- Model fine-tuning with progress tracking\n",
    "- Training visualization\n",
    "- Model testing on diverse examples\n",
    "- Comprehensive ROUGE evaluation\n",
    "- Safety checks and logging\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `models/appetite_bart_best/` - Fine-tuned model\n",
    "- `training_progress.png` - Training charts\n",
    "- `evaluation_results/` - ROUGE scores\n",
    "- `training_logs/` - Training history\n",
    "- `logs/predictions.jsonl` - All predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd175f33-96b1-471e-8eda-7a6561df8582",
   "metadata": {},
   "source": [
    "# Risk Management and Trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f2aff-7ae0-4084-89dd-b8e71ce9cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def check_dataset_quality(df):\n",
    "    print(\"Data Quality Check\")\n",
    "    print(\"Rows:\", len(df), \", Columns:\", len(df.columns))\n",
    "    print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "    print(\"Duplicate Rows:\", df.duplicated().sum())\n",
    "    \n",
    "    # Fix here ‚Äî handle both naming cases safely\n",
    "    category_col = None\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'category':\n",
    "            category_col = col\n",
    "            break\n",
    "    \n",
    "    if category_col:\n",
    "        print(\"Category Distribution:\\n\", df[category_col].value_counts())\n",
    "    else:\n",
    "        print(\"No 'category' column found in dataset.\")\n",
    "    \n",
    "    print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcb9a6-489a-4028-880f-2586094e53d9",
   "metadata": {},
   "source": [
    "**Safety & Allergen Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a156d6a-c6e6-4723-80ee-a049a1b6692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLERGENS = ['peanut', 'milk', 'egg', 'soy', 'fish', 'shellfish', 'wheat', 'gluten', 'sesame']\n",
    "\n",
    "def detect_allergens(text):\n",
    "    found = [a for a in ALLERGENS if re.search(rf'\\b{a}\\b', str(text).lower())]\n",
    "    return found\n",
    "\n",
    "def safety_check(recipe_text):\n",
    "    if detect_allergens(recipe_text):\n",
    "        print(f\"Warning: Contains allergens: {detect_allergens(recipe_text)}\")\n",
    "    if any(bad in recipe_text.lower() for bad in ['kill', 'poison', 'suicide']):\n",
    "        print(\"Unsafe content detected! Review required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a743e4-134c-43f5-8731-e94dd3179828",
   "metadata": {},
   "source": [
    "**Simple Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d45306-30fb-4982-825b-15e803fdad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prediction(input_text, output_text):\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"input\": input_text,\n",
    "        \"output\": output_text\n",
    "    }\n",
    "    with open(\"logs/predictions.jsonl\", \"a\") as f:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "    print(\" Logged prediction for monitoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed32f56-23ab-4f9b-8304-a89b30c51247",
   "metadata": {},
   "source": [
    "**Trustworthy Model Card Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf50fd-ca0d-4a29-bdfa-4dd6e4bfcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_card(name=\"AppetIte-BART\", version=\"v1.0\"):\n",
    "    card = f\"\"\"\n",
    "# Model Card: {name}\n",
    "**Version:** {version}\n",
    "**Purpose:** Generate recipes from ingredients.\n",
    "**Training Data:** Curated AppetIte_Dataset.csv\n",
    "**Risks:** May include allergen ingredients or biased cuisine categories.\n",
    "**Mitigations:** Allergen filter, user feedback, manual review.\n",
    "**Contact:** Sharath / Project Maintainer\n",
    "\"\"\"\n",
    "    with open(\"MODEL_CARD.md\", \"w\") as f:\n",
    "        f.write(card)\n",
    "    print(\" Model Card created (MODEL_CARD.md)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affee609-a171-43eb-9952-e16d234dfa27",
   "metadata": {},
   "source": [
    "**Example Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e549d-9188-406c-a444-519f7f0a1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/curated/AppetIte_Dataset_v1.csv\")\n",
    "\n",
    "check_dataset_quality(df)\n",
    "\n",
    "sample_input = \"ingredients: peanut butter, banana, honey\"\n",
    "sample_output = \"peanut butter banana smoothie\"\n",
    "\n",
    "safety_check(sample_output)\n",
    "\n",
    "log_prediction(sample_input, sample_output)\n",
    "\n",
    "create_model_card()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
