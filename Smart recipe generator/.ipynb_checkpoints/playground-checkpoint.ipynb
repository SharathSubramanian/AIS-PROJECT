{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750c72a4-2974-43ef-b4d4-a473832e0783",
   "metadata": {},
   "source": [
    "# Homework - Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656a5d1f-d419-4852-8b0c-f3c294e38308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490bab2d-9e85-4c9f-9984-cc2c6b1d77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"AppetIte_Dataset.csv\"\n",
    "appetite_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e974b9-6687-4500-a272-55f9ba56deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Dataset Information ===\n",
      "Total Records: 13501\n",
      "Total Features: 8\n",
      "\n",
      "Column Names:\n",
      "['recipe_id', 'recipe_name', 'ingredients', 'instructions', 'image_path', 'category', 'storage_tips', 'nutrition_score']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Basic Dataset Information ===\")\n",
    "print(f\"Total Records: {appetite_df.shape[0]}\")\n",
    "print(f\"Total Features: {appetite_df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(appetite_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf34ee2f-f5ba-402f-91e8-4742ef782963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Data Types & Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13501 entries, 0 to 13500\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   recipe_id        13501 non-null  int64  \n",
      " 1   recipe_name      13501 non-null  int64  \n",
      " 2   ingredients      13501 non-null  object \n",
      " 3   instructions     13493 non-null  object \n",
      " 4   image_path       13501 non-null  object \n",
      " 5   category         13501 non-null  object \n",
      " 6   storage_tips     13501 non-null  object \n",
      " 7   nutrition_score  13501 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 843.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Data Types & Non-Null Counts:\")\n",
    "print(appetite_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd99eab2-7638-4670-a3da-46f22b759bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary Statistics (for numeric columns) ===\n",
      "                   count unique  \\\n",
      "recipe_id        13501.0    NaN   \n",
      "recipe_name      13501.0    NaN   \n",
      "ingredients        13501  13473   \n",
      "instructions       13493  13464   \n",
      "image_path         13501  13472   \n",
      "category           13501      4   \n",
      "storage_tips       13501      1   \n",
      "nutrition_score  13501.0    NaN   \n",
      "\n",
      "                                                               top   freq  \\\n",
      "recipe_id                                                      NaN    NaN   \n",
      "recipe_name                                                    NaN    NaN   \n",
      "ingredients                                                     []     12   \n",
      "instructions     place ingredients in blender in the order list...      5   \n",
      "image_path                                                  #NAME?     30   \n",
      "category                                                 Indulgent  10685   \n",
      "storage_tips     Store ingredients in airtight containers; refr...  13501   \n",
      "nutrition_score                                                NaN    NaN   \n",
      "\n",
      "                     mean          std  min     25%     50%      75%      max  \n",
      "recipe_id          6751.0  3897.547327  1.0  3376.0  6751.0  10126.0  13501.0  \n",
      "recipe_name        6750.0  3897.547327  0.0  3375.0  6750.0  10125.0  13500.0  \n",
      "ingredients           NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "instructions          NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "image_path            NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "category              NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "storage_tips          NaN          NaN  NaN     NaN     NaN      NaN      NaN  \n",
      "nutrition_score  0.775893     0.101012  0.6    0.69    0.78     0.86     0.95  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Summary Statistics (for numeric columns) ===\")\n",
    "print(appetite_df.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219e4e4b-7278-417e-864f-10e9d5762e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Data (first 5 rows) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>image_path</th>\n",
       "      <th>category</th>\n",
       "      <th>storage_tips</th>\n",
       "      <th>nutrition_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['1 (3¬Ω‚Äì4-lb.) whole chicken', '2¬æ tsp. kosher...</td>\n",
       "      <td>pat chicken dry with paper towels, season all ...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "      <td>preheat oven to 400¬∞f and line a rimmed baking...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "      <td>place a rack in middle of oven; preheat to 400...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>['1 (¬æ- to 1-pound) round italian loaf, cut in...</td>\n",
       "      <td>preheat oven to 350¬∞f with rack in middle. gen...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "      <td>stir together brown sugar and hot water in a c...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>Quick Meals</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  recipe_name                                        ingredients  \\\n",
       "0          1            0  ['1 (3¬Ω‚Äì4-lb.) whole chicken', '2¬æ tsp. kosher...   \n",
       "1          2            1  ['2 large egg whites', '1 pound new potatoes (...   \n",
       "2          3            2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
       "3          4            3  ['1 (¬æ- to 1-pound) round italian loaf, cut in...   \n",
       "4          5            4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  pat chicken dry with paper towels, season all ...   \n",
       "1  preheat oven to 400¬∞f and line a rimmed baking...   \n",
       "2  place a rack in middle of oven; preheat to 400...   \n",
       "3  preheat oven to 350¬∞f with rack in middle. gen...   \n",
       "4  stir together brown sugar and hot water in a c...   \n",
       "\n",
       "                                          image_path     category  \\\n",
       "0  miso-butter-roast-chicken-acorn-squash-panzanella    Indulgent   \n",
       "1         crispy-salt-and-pepper-potatoes-dan-kluger    Indulgent   \n",
       "2         thanksgiving-mac-and-cheese-erick-williams    Indulgent   \n",
       "3          italian-sausage-and-bread-stuffing-240559      Healthy   \n",
       "4                 newtons-law-apple-bourbon-cocktail  Quick Meals   \n",
       "\n",
       "                                        storage_tips  nutrition_score  \n",
       "0  Store ingredients in airtight containers; refr...             0.63  \n",
       "1  Store ingredients in airtight containers; refr...             0.83  \n",
       "2  Store ingredients in airtight containers; refr...             0.68  \n",
       "3  Store ingredients in airtight containers; refr...             0.69  \n",
       "4  Store ingredients in airtight containers; refr...             0.65  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n=== Sample Data (first 5 rows) ===\")\n",
    "display(appetite_df.head())\n",
    "curated_path = \"data/curated/AppetIte_Dataset_v1.csv\"\n",
    "os.makedirs(\"data/curated\", exist_ok=True)\n",
    "appetite_df.to_csv(curated_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4b8da-e76c-40fd-b4da-fbe5180b94c5",
   "metadata": {},
   "source": [
    "# Homework - Model development (The very first steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86877c0-b2b7-4ce9-87ce-04f2837cff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aml/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150cfddc-f80c-459d-ae8a-63c94fa7977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3cb962f-7513-4a99-9096-8cee1410ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef1b9c7-1b14-49f6-84b6-f8526bcb7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'facebook/bart-large-cnn' loaded successfully on device: mps\n",
      "Number of parameters: 406,290,432\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model '{model_name}' loaded successfully on device: {device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02351f8d-2902-4296-9bf6-e3dca3ca62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = [\n",
    "    \"ingredients: chicken, rice, soy sauce, garlic, egg\",\n",
    "    \"ingredients: spinach, tomato, feta cheese, olive oil\",\n",
    "    \"ingredients: oats, honey, banana, milk\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129cf67-f3db-49cf-99d8-f4686c4602c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Input: ingredients: chicken, rice, soy sauce, garlic, egg\n",
      " Generated Recipe Suggestion: ingredients: chicken, rice, soy sauce, garlic, egg, egg and rice. Serves 8 people at a time\n",
      "\n",
      "üßæ Input: ingredients: spinach, tomato, feta cheese, olive oil\n",
      " Generated Recipe Suggestion: ingredients: spinach, tomato, feta cheese, olive oil and olive oil. Serves 2-3 people at a\n",
      "\n",
      "üßæ Input: ingredients: oats, honey, banana, milk\n",
      " Generated Recipe Suggestion: ingredients: oats, honey, banana, milk, milk. Serves 4 people. For more information, visit www.\n"
     ]
    }
   ],
   "source": [
    "for text in sample_inputs:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=30,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    print(f\"\\nüßæ Input: {text}\")\n",
    "    print(f\" Generated Recipe Suggestion: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bddaf39-7258-42c5-a3c5-a5b0ea221ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Embedding shape: (1, 1024)\n",
      "These embeddings can be used for clustering or category classifiers (Healthy, Quick, etc.).\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sample_inputs[0], return_tensors=\"pt\").to(device)\n",
    "    outputs = model.model.encoder(**inputs, output_hidden_states=True)\n",
    "    # Grab last hidden state\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "print(\"\\n Embedding shape:\", embeddings.shape)\n",
    "print(\"These embeddings can be used for clustering or category classifiers (Healthy, Quick, etc.).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31591fc0-e80c-4ceb-a0dd-d6e70f506ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Example Generated Output:\n",
      "ingredients: pasta, tomato, garlic, olive oil, basil, basil. Serves 4-6 people. For more information, go to www.gofundme.com/sauceof pasta. For\n"
     ]
    }
   ],
   "source": [
    "test_input = \"ingredients: pasta, tomato, garlic, olive oil, basil\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(**inputs, max_length=50, num_beams=4, early_stopping=True)\n",
    "recipe_output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n Example Generated Output:\")\n",
    "print(recipe_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c854e9c-daea-4819-b37a-ba56f07ce823",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "- Fine-tune on curated AppetIte_Dataset.csv (input_text ‚Üí target_text)\n",
    "- Evaluate recipe coherence & category alignment\n",
    "- Optionally distill or prune model for lower latency (<2 s goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf0bd0",
   "metadata": {},
   "source": [
    "# Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c62e9102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 11,475\n",
      "Validation samples: 2,026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/curated/AppetIte_Dataset_v1.csv\")\n",
    "\n",
    "def prepare_input_text(row):\n",
    "    ingredients = row['ingredients'] if pd.notna(row['ingredients']) else 'no ingredients listed'\n",
    "    category = row['category'] if pd.notna(row['category']) else 'general'\n",
    "    return f\"Generate a {category} recipe using: {ingredients}\"\n",
    "\n",
    "def prepare_target_text(row):\n",
    "    recipe_name = row['recipe_name'] if pd.notna(row['recipe_name']) else 'Delicious Recipe'\n",
    "    instructions = row['instructions'] if pd.notna(row['instructions']) else 'Instructions not available'\n",
    "    return f\"Recipe: {recipe_name}. Instructions: {instructions}\"\n",
    "\n",
    "df['input_text'] = df.apply(prepare_input_text, axis=1)\n",
    "df['target_text'] = df.apply(prepare_target_text, axis=1)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['category'])\n",
    "\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdd3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 11,475 examples\n",
      "Validation dataset: 2,026 examples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_length=256, max_target_length=512):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.data.loc[idx, 'input_text']\n",
    "        target_text = self.data.loc[idx, 'target_text']\n",
    "        \n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        labels = target_encoding['input_ids'].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "train_dataset = RecipeDataset(train_df, tokenizer)\n",
    "val_dataset = RecipeDataset(val_df, tokenizer)\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset):,} examples\")\n",
    "print(f\"Validation dataset: {len(val_dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a246d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1\n",
      "Effective batch size: 8\n",
      "Total steps: 2,868\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "LEARNING_RATE = 3e-5\n",
    "BATCH_SIZE = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 8\n",
    "EPOCHS = 2\n",
    "MAX_INPUT_LENGTH = 128\n",
    "MAX_TARGET_LENGTH = 256\n",
    "WARMUP_STEPS=100\n",
    "\n",
    "# Create datasets with reduced sequence lengths\n",
    "train_dataset = RecipeDataset(train_df, tokenizer, max_input_length=128, max_target_length=256)\n",
    "val_dataset = RecipeDataset(val_df, tokenizer, max_input_length=128, max_target_length=256)\n",
    "\n",
    "# Recreate data loaders with new batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Recreate optimizer and scheduler with updated steps\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * EPOCHS // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"Total steps: {total_steps:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4207203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Validating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            progress_bar.set_postfix({'Val Loss': f'{outputs.loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42bb42af-c343-49a7-81eb-84b785b0fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a869496-7582-4168-9174-3cb8299fad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92a947c2-810b-4cc7-b99c-3cee30f97f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff8d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started: 2025-11-02 20:24:51\n",
      "Training on 11,475 recipes\n",
      "Validating on 2,026 recipes\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440645a1f6814339aaf8bec128e08979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/11475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"training_logs\", exist_ok=True)\n",
    "\n",
    "print(f\"Training started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Training on {len(train_dataset):,} recipes\")\n",
    "print(f\"Validating on {len(val_dataset):,} recipes\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "training_history = {'train_loss': [], 'val_loss': [], 'epoch_times': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    \n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    training_history['epoch_times'].append(epoch_time)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Time: {epoch_time/60:.1f} minutes\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"New best model, saving...\")\n",
    "        \n",
    "        model.save_pretrained(\"models/appetite_bart_best\")\n",
    "        tokenizer.save_pretrained(\"models/appetite_bart_best\")\n",
    "        \n",
    "        model_info = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'training_time': sum(training_history['epoch_times']),\n",
    "            'date_saved': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open('models/appetite_bart_best/training_info.json', 'w') as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(f\"\\nTraining complete\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "with open('training_logs/training_history.json', 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0218d570",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m epochs_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_range, training_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_range, training_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.12/site-packages/matplotlib/pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   3830\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   3831\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[1;32m   3832\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   3833\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3834\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3835\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.12/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[1;32m    298\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey,\n\u001b[1;32m    299\u001b[0m     return_kwargs\u001b[38;5;241m=\u001b[39mreturn_kwargs\n\u001b[1;32m    300\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.12/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(1, EPOCHS + 1)\n",
    "plt.plot(epochs_range, training_history['train_loss'], 'o-', label='Training Loss', linewidth=2)\n",
    "plt.plot(epochs_range, training_history['val_loss'], 's-', label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "epoch_times_minutes = [t/60 for t in training_history['epoch_times']]\n",
    "plt.bar(epochs_range, epoch_times_minutes, alpha=0.7, color='coral')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Time (minutes)')\n",
    "plt.title('Training Time per Epoch')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_progress.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ee0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "finetuned_model = BartForConditionalGeneration.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_tokenizer = BartTokenizer.from_pretrained(\"models/appetite_bart_best\")\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "print(\"Fine-tuned model loaded\")\n",
    "\n",
    "try:\n",
    "    with open('models/appetite_bart_best/training_info.json', 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    print(f\"Best epoch: {training_info['epoch']}\")\n",
    "    print(f\"Validation loss: {training_info['val_loss']:.4f}\")\n",
    "    print(f\"Training time: {training_info['training_time']/60:.1f} minutes\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recipes = [\n",
    "    \"Generate a Healthy recipe using: ['chicken breast', 'broccoli', 'olive oil', 'garlic', 'lemon', 'quinoa']\",\n",
    "    \"Generate a Quick Meals recipe using: ['pasta', 'tomato sauce', 'basil', 'mozzarella cheese', 'garlic']\",\n",
    "    \"Generate an Indulgent recipe using: ['dark chocolate', 'heavy cream', 'butter', 'vanilla extract', 'eggs']\"\n",
    "]\n",
    "\n",
    "finetuned_model.eval()\n",
    "\n",
    "for i, test_input in enumerate(test_recipes, 1):\n",
    "    print(f\"\\nTest {i}\")\n",
    "    \n",
    "    inputs = finetuned_tokenizer(test_input, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        generated_ids = finetuned_model.generate(\n",
    "            **inputs,\n",
    "            max_length=250,\n",
    "            num_beams=5,\n",
    "            temperature=0.8,\n",
    "            do_sample=True,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    ai_recipe = finetuned_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Generated Recipe: {ai_recipe}\")\n",
    "    print(f\"Generation time: {generation_time:.2f}s\")\n",
    "    print(f\"Length: {len(ai_recipe)} characters\")\n",
    "    \n",
    "    allergens = detect_allergens(ai_recipe)\n",
    "    if allergens:\n",
    "        print(f\"Allergens: {', '.join(allergens)}\")\n",
    "    \n",
    "    log_prediction(test_input, ai_recipe)\n",
    "\n",
    "print(\"\\nTesting complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from rouge_score import rouge_scorer\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', 'rouge-score'], check=True)\n",
    "    from rouge_score import rouge_scorer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, tokenizer, val_df, device, num_samples=100):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    generation_times = []\n",
    "    output_lengths = []\n",
    "    \n",
    "    model.eval()\n",
    "    sample_indices = np.random.choice(len(val_df), min(num_samples, len(val_df)), replace=False)\n",
    "    \n",
    "    for idx_num, idx in enumerate(sample_indices, 1):\n",
    "        if idx_num % 20 == 0:\n",
    "            print(f\"Progress: {idx_num}/{len(sample_indices)}\")\n",
    "        \n",
    "        input_text = val_df.iloc[idx]['input_text']\n",
    "        reference_text = val_df.iloc[idx]['target_text']\n",
    "        \n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_length=250, num_beams=4, early_stopping=True)\n",
    "        generation_time = time.time() - start_time\n",
    "        \n",
    "        prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        try:\n",
    "            scores = scorer.score(reference_text, prediction)\n",
    "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        except:\n",
    "            rouge1_scores.append(0.0)\n",
    "            rouge2_scores.append(0.0)\n",
    "            rougeL_scores.append(0.0)\n",
    "        \n",
    "        generation_times.append(generation_time)\n",
    "        output_lengths.append(len(prediction))\n",
    "    \n",
    "    results = {\n",
    "        'rouge1_mean': np.mean(rouge1_scores),\n",
    "        'rouge1_std': np.std(rouge1_scores),\n",
    "        'rouge2_mean': np.mean(rouge2_scores),\n",
    "        'rouge2_std': np.std(rouge2_scores),\n",
    "        'rougeL_mean': np.mean(rougeL_scores),\n",
    "        'rougeL_std': np.std(rougeL_scores),\n",
    "        'avg_generation_time': np.mean(generation_times),\n",
    "        'avg_output_length': np.mean(output_lengths),\n",
    "        'samples_evaluated': len(sample_indices)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Starting evaluation\")\n",
    "eval_results = evaluate_model(finetuned_model, finetuned_tokenizer, val_df, device, num_samples=min(100, len(val_df)))\n",
    "\n",
    "print(\"\\nEvaluation Results\")\n",
    "print(f\"ROUGE-1: {eval_results['rouge1_mean']:.4f} ¬± {eval_results['rouge1_std']:.4f}\")\n",
    "print(f\"ROUGE-2: {eval_results['rouge2_mean']:.4f} ¬± {eval_results['rouge2_std']:.4f}\")\n",
    "print(f\"ROUGE-L: {eval_results['rougeL_mean']:.4f} ¬± {eval_results['rougeL_std']:.4f}\")\n",
    "print(f\"Avg generation time: {eval_results['avg_generation_time']:.3f}s\")\n",
    "print(f\"Avg output length: {eval_results['avg_output_length']:.0f} characters\")\n",
    "print(f\"Samples evaluated: {eval_results['samples_evaluated']}\")\n",
    "\n",
    "overall_rouge = (eval_results['rouge1_mean'] + eval_results['rouge2_mean'] + eval_results['rougeL_mean']) / 3\n",
    "print(f\"Overall ROUGE: {overall_rouge:.4f}\")\n",
    "\n",
    "os.makedirs('evaluation_results', exist_ok=True)\n",
    "with open('evaluation_results/comprehensive_evaluation.json', 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "\n",
    "print(\"Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f951c",
   "metadata": {},
   "source": [
    "# Model Development Complete\n",
    "\n",
    "## Completed Steps\n",
    "\n",
    "- Data preparation with train/validation split\n",
    "- PyTorch dataset implementation\n",
    "- Model fine-tuning with progress tracking\n",
    "- Training visualization\n",
    "- Model testing on diverse examples\n",
    "- Comprehensive ROUGE evaluation\n",
    "- Safety checks and logging\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `models/appetite_bart_best/` - Fine-tuned model\n",
    "- `training_progress.png` - Training charts\n",
    "- `evaluation_results/` - ROUGE scores\n",
    "- `training_logs/` - Training history\n",
    "- `logs/predictions.jsonl` - All predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd175f33-96b1-471e-8eda-7a6561df8582",
   "metadata": {},
   "source": [
    "# Risk Management and Trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f07f2aff-7ae0-4084-89dd-b8e71ce9cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def check_dataset_quality(df):\n",
    "    print(\"Data Quality Check\")\n",
    "    print(\"Rows:\", len(df), \", Columns:\", len(df.columns))\n",
    "    print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "    print(\"Duplicate Rows:\", df.duplicated().sum())\n",
    "    \n",
    "    # Fix here ‚Äî handle both naming cases safely\n",
    "    category_col = None\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'category':\n",
    "            category_col = col\n",
    "            break\n",
    "    \n",
    "    if category_col:\n",
    "        print(\"Category Distribution:\\n\", df[category_col].value_counts())\n",
    "    else:\n",
    "        print(\"No 'category' column found in dataset.\")\n",
    "    \n",
    "    print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcb9a6-489a-4028-880f-2586094e53d9",
   "metadata": {},
   "source": [
    "**Safety & Allergen Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a156d6a-c6e6-4723-80ee-a049a1b6692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLERGENS = ['peanut', 'milk', 'egg', 'soy', 'fish', 'shellfish', 'wheat', 'gluten', 'sesame']\n",
    "\n",
    "def detect_allergens(text):\n",
    "    found = [a for a in ALLERGENS if re.search(rf'\\b{a}\\b', str(text).lower())]\n",
    "    return found\n",
    "\n",
    "def safety_check(recipe_text):\n",
    "    if detect_allergens(recipe_text):\n",
    "        print(f\"Warning: Contains allergens: {detect_allergens(recipe_text)}\")\n",
    "    if any(bad in recipe_text.lower() for bad in ['kill', 'poison', 'suicide']):\n",
    "        print(\"Unsafe content detected! Review required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a743e4-134c-43f5-8731-e94dd3179828",
   "metadata": {},
   "source": [
    "**Simple Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6d45306-30fb-4982-825b-15e803fdad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prediction(input_text, output_text):\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"input\": input_text,\n",
    "        \"output\": output_text\n",
    "    }\n",
    "    with open(\"logs/predictions.jsonl\", \"a\") as f:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "    print(\" Logged prediction for monitoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed32f56-23ab-4f9b-8304-a89b30c51247",
   "metadata": {},
   "source": [
    "**Trustworthy Model Card Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08bf50fd-ca0d-4a29-bdfa-4dd6e4bfcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_card(name=\"AppetIte-BART\", version=\"v1.0\"):\n",
    "    card = f\"\"\"\n",
    "# Model Card: {name}\n",
    "**Version:** {version}\n",
    "**Purpose:** Generate recipes from ingredients.\n",
    "**Training Data:** Curated AppetIte_Dataset.csv\n",
    "**Risks:** May include allergen ingredients or biased cuisine categories.\n",
    "**Mitigations:** Allergen filter, user feedback, manual review.\n",
    "**Contact:** Sharath / Project Maintainer\n",
    "\"\"\"\n",
    "    with open(\"MODEL_CARD.md\", \"w\") as f:\n",
    "        f.write(card)\n",
    "    print(\" Model Card created (MODEL_CARD.md)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affee609-a171-43eb-9952-e16d234dfa27",
   "metadata": {},
   "source": [
    "**Example Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "820e549d-9188-406c-a444-519f7f0a1018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Check\n",
      "Rows: 13501 , Columns: 8\n",
      "Missing Values:\n",
      " recipe_id          0\n",
      "recipe_name        0\n",
      "ingredients        0\n",
      "instructions       8\n",
      "image_path         0\n",
      "category           0\n",
      "storage_tips       0\n",
      "nutrition_score    0\n",
      "dtype: int64\n",
      "Duplicate Rows: 0\n",
      "Category Distribution:\n",
      " category\n",
      "Indulgent          10685\n",
      "Healthy             1437\n",
      "Quick Meals         1308\n",
      "Family-Friendly       71\n",
      "Name: count, dtype: int64\n",
      "==========================\n",
      "Warning: Contains allergens: ['peanut']\n",
      " Logged prediction for monitoring.\n",
      " Model Card created (MODEL_CARD.md)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/nw2d4nm51zj7xgfrvxnrzz440000gn/T/ipykernel_60955/1022548407.py:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/curated/AppetIte_Dataset_v1.csv\")\n",
    "\n",
    "check_dataset_quality(df)\n",
    "\n",
    "sample_input = \"ingredients: peanut butter, banana, honey\"\n",
    "sample_output = \"peanut butter banana smoothie\"\n",
    "\n",
    "safety_check(sample_output)\n",
    "\n",
    "log_prediction(sample_input, sample_output)\n",
    "\n",
    "create_model_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19683d22-7ba8-4c2e-b439-a090653a0f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
