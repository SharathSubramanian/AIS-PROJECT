{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc3dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch pandas scikit-learn tqdm rouge-score -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94706e54",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9767d1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Total records: 13501\n",
      "Categories: {'Indulgent': 10685, 'Healthy': 1437, 'Quick Meals': 1308, 'Family-Friendly': 71}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "df = pd.read_csv('AppetIte_Dataset_v1.csv')\n",
    "print(f'Total records: {len(df)}')\n",
    "print(f'Categories: {df[\"category\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc187b7-25dc-4901-943e-11e10bee0f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077f5cad-eeaa-411b-856e-ca7b9af385b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 13501\n",
      "Categories: {'Indulgent': 10685, 'Healthy': 1437, 'Quick Meals': 1308, 'Family-Friendly': 71}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('AppetIte_Dataset_v1.csv')\n",
    "print(f'Total records: {len(df)}')\n",
    "print(f'Categories: {df[\"category\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d10ae9-187f-466f-a06d-6e9157aa5c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>image_path</th>\n",
       "      <th>category</th>\n",
       "      <th>storage_tips</th>\n",
       "      <th>nutrition_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n",
       "      <td>pat chicken dry with paper towels, season all ...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n",
       "      <td>preheat oven to 400°f and line a rimmed baking...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>['1 cup evaporated milk', '1 cup whole milk', ...</td>\n",
       "      <td>place a rack in middle of oven; preheat to 400...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>['1 (¾- to 1-pound) round italian loaf, cut in...</td>\n",
       "      <td>preheat oven to 350°f with rack in middle. gen...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>['1 teaspoon dark brown sugar', '1 teaspoon ho...</td>\n",
       "      <td>stir together brown sugar and hot water in a c...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>Quick Meals</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>13497</td>\n",
       "      <td>13496</td>\n",
       "      <td>['1 cup all-purpose flour', '2/3 cup unsweeten...</td>\n",
       "      <td>preheat the oven to 350°f. into a bowl sift to...</td>\n",
       "      <td>brownie-pudding-cake-14408</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>13498</td>\n",
       "      <td>13497</td>\n",
       "      <td>['1 preserved lemon', '1 1/2 pound butternut s...</td>\n",
       "      <td>preheat oven to 475°f. halve lemons and scoop ...</td>\n",
       "      <td>israeli-couscous-with-roasted-butternut-squash...</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>13499</td>\n",
       "      <td>13498</td>\n",
       "      <td>['leftover katsuo bushi (dried bonito flakes) ...</td>\n",
       "      <td>if using katsuo bushi flakes from package, moi...</td>\n",
       "      <td>rice-with-soy-glazed-bonito-flakes-and-sesame-...</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>13500</td>\n",
       "      <td>13499</td>\n",
       "      <td>['1 stick (1/2 cup) plus 1 tablespoon unsalted...</td>\n",
       "      <td>melt 1 tablespoon butter in a 12-inch heavy sk...</td>\n",
       "      <td>spanakopita-107344</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13500</th>\n",
       "      <td>13501</td>\n",
       "      <td>13500</td>\n",
       "      <td>['12 medium to large fresh poblano chiles (2 1...</td>\n",
       "      <td>lay 4 chiles on their sides on racks of gas bu...</td>\n",
       "      <td>mexican-poblano-spinach-and-black-bean-lasagne...</td>\n",
       "      <td>Indulgent</td>\n",
       "      <td>Store ingredients in airtight containers; refr...</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13501 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       recipe_id  recipe_name  \\\n",
       "0              1            0   \n",
       "1              2            1   \n",
       "2              3            2   \n",
       "3              4            3   \n",
       "4              5            4   \n",
       "...          ...          ...   \n",
       "13496      13497        13496   \n",
       "13497      13498        13497   \n",
       "13498      13499        13498   \n",
       "13499      13500        13499   \n",
       "13500      13501        13500   \n",
       "\n",
       "                                             ingredients  \\\n",
       "0      ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
       "1      ['2 large egg whites', '1 pound new potatoes (...   \n",
       "2      ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
       "3      ['1 (¾- to 1-pound) round italian loaf, cut in...   \n",
       "4      ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
       "...                                                  ...   \n",
       "13496  ['1 cup all-purpose flour', '2/3 cup unsweeten...   \n",
       "13497  ['1 preserved lemon', '1 1/2 pound butternut s...   \n",
       "13498  ['leftover katsuo bushi (dried bonito flakes) ...   \n",
       "13499  ['1 stick (1/2 cup) plus 1 tablespoon unsalted...   \n",
       "13500  ['12 medium to large fresh poblano chiles (2 1...   \n",
       "\n",
       "                                            instructions  \\\n",
       "0      pat chicken dry with paper towels, season all ...   \n",
       "1      preheat oven to 400°f and line a rimmed baking...   \n",
       "2      place a rack in middle of oven; preheat to 400...   \n",
       "3      preheat oven to 350°f with rack in middle. gen...   \n",
       "4      stir together brown sugar and hot water in a c...   \n",
       "...                                                  ...   \n",
       "13496  preheat the oven to 350°f. into a bowl sift to...   \n",
       "13497  preheat oven to 475°f. halve lemons and scoop ...   \n",
       "13498  if using katsuo bushi flakes from package, moi...   \n",
       "13499  melt 1 tablespoon butter in a 12-inch heavy sk...   \n",
       "13500  lay 4 chiles on their sides on racks of gas bu...   \n",
       "\n",
       "                                              image_path     category  \\\n",
       "0      miso-butter-roast-chicken-acorn-squash-panzanella    Indulgent   \n",
       "1             crispy-salt-and-pepper-potatoes-dan-kluger    Indulgent   \n",
       "2             thanksgiving-mac-and-cheese-erick-williams    Indulgent   \n",
       "3              italian-sausage-and-bread-stuffing-240559      Healthy   \n",
       "4                     newtons-law-apple-bourbon-cocktail  Quick Meals   \n",
       "...                                                  ...          ...   \n",
       "13496                         brownie-pudding-cake-14408    Indulgent   \n",
       "13497  israeli-couscous-with-roasted-butternut-squash...    Indulgent   \n",
       "13498  rice-with-soy-glazed-bonito-flakes-and-sesame-...    Indulgent   \n",
       "13499                                 spanakopita-107344    Indulgent   \n",
       "13500  mexican-poblano-spinach-and-black-bean-lasagne...    Indulgent   \n",
       "\n",
       "                                            storage_tips  nutrition_score  \n",
       "0      Store ingredients in airtight containers; refr...             0.63  \n",
       "1      Store ingredients in airtight containers; refr...             0.83  \n",
       "2      Store ingredients in airtight containers; refr...             0.68  \n",
       "3      Store ingredients in airtight containers; refr...             0.69  \n",
       "4      Store ingredients in airtight containers; refr...             0.65  \n",
       "...                                                  ...              ...  \n",
       "13496  Store ingredients in airtight containers; refr...             0.77  \n",
       "13497  Store ingredients in airtight containers; refr...             0.70  \n",
       "13498  Store ingredients in airtight containers; refr...             0.83  \n",
       "13499  Store ingredients in airtight containers; refr...             0.87  \n",
       "13500  Store ingredients in airtight containers; refr...             0.94  \n",
       "\n",
       "[13501 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a287a46-ffc6-4cf5-8647-3b6abee85a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13501 entries, 0 to 13500\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   recipe_id        13501 non-null  int64  \n",
      " 1   recipe_name      13501 non-null  int64  \n",
      " 2   ingredients      13501 non-null  object \n",
      " 3   instructions     13493 non-null  object \n",
      " 4   image_path       13501 non-null  object \n",
      " 5   category         13501 non-null  object \n",
      " 6   storage_tips     13501 non-null  object \n",
      " 7   nutrition_score  13501 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 843.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aea98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_text(row):\n",
    "    ingredients = row['ingredients'] if pd.notna(row['ingredients']) else 'no ingredients listed'\n",
    "    category = row['category'] if pd.notna(row['category']) else 'general'\n",
    "    return f\"Generate a {category} recipe using: {ingredients}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315dbb05-b1b1-4d20-9c1f-a6545fe2913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target_text(row):\n",
    "    recipe_name = row['recipe_name'] if pd.notna(row['recipe_name']) else 'Delicious Recipe'\n",
    "    instructions = row['instructions'] if pd.notna(row['instructions']) else 'Instructions not available'\n",
    "    return f\"Recipe: {recipe_name}. Instructions: {instructions}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77db992-1190-4ed4-97d5-3ca0303d9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_text'] = df.apply(prepare_input_text, axis=1)\n",
    "df['target_text'] = df.apply(prepare_target_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4919095e-6989-45c1-83bf-825d344cc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['category'])\n",
    "\n",
    "train_df = train_df.head(100).reset_index(drop=True)\n",
    "val_df = val_df.head(25).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37a28bb-69ad-47a6-9168-d88568bc9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 100\n",
      "Validation samples: 25\n"
     ]
    }
   ],
   "source": [
    "print(f'Training samples: {len(train_df)}')\n",
    "print(f'Validation samples: {len(val_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86950e94",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained BART Model (Smaller Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e143479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facebook/bart-base'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125805ac-0d5f-44ce-aff6-dd3f47c1f4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: facebook/bart-base\n",
      "Number of parameters: 139,420,416\n"
     ]
    }
   ],
   "source": [
    "print(f'Model loaded: {model_name}')\n",
    "print(f'Number of parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1240c",
   "metadata": {},
   "source": [
    "## 3. Test Pre-trained Model (Before Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddfea6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = [\n",
    "    \"Generate a Healthy recipe using: chicken, rice, broccoli, garlic\",\n",
    "    \"Generate a Quick Meals recipe using: pasta, tomato sauce, basil\",\n",
    "    \"Generate an Indulgent recipe using: chocolate, cream, butter\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1feb5692-003e-4593-a52d-166b97249847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pre-trained model:\n",
      "\n",
      "Input: Generate a Healthy recipe using: chicken, rice, broccoli, garlic\n",
      "Output: Generate a Healthy recipe using: chicken, rice, broccoli, garlic\n",
      "\n",
      "Input: Generate a Quick Meals recipe using: pasta, tomato sauce, basil\n",
      "Output: Generate a Quick Meals recipe using: pasta, tomato sauce, basil\n",
      "\n",
      "Input: Generate an Indulgent recipe using: chocolate, cream, butter\n",
      "Output: Generate an Indulgent recipe using: chocolate, cream, butter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing pre-trained model:\\n')\n",
    "model.eval()\n",
    "\n",
    "for text in sample_inputs:\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=128, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            temperature=0.8,\n",
    "            do_sample=False  # Deterministic for testing\n",
    "        )\n",
    "    \n",
    "    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    print(f'Input: {text}')\n",
    "    print(f'Output: {output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9a881",
   "metadata": {},
   "source": [
    "## 4. Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d33f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_input_length=128, max_target_length=200):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.data.loc[idx, 'input_text']\n",
    "        target_text = self.data.loc[idx, 'target_text']\n",
    "\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        labels = target_encoding['input_ids'].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100  \n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }\n",
    "train_dataset = RecipeDataset(train_df, tokenizer)\n",
    "val_dataset = RecipeDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed663787-4d32-40c1-bca4-ccf8b6852c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 100\n",
      "Validation dataset size: 25\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194f2e1",
   "metadata": {},
   "source": [
    "## 5. Fine-tune Model (Optimized for Speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3267a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2  \n",
    "GRADIENT_ACCUMULATION_STEPS = 4  \n",
    "EPOCHS = 3  \n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734d4dca-2914-4d34-b634-62bda1baa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0132a363-0023-4986-aa4f-35667f34391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = (len(train_loader) // GRADIENT_ACCUMULATION_STEPS) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49482f54-5e40-4838-8dcc-975bd6211915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 36\n",
      "Effective batch size: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Total training steps: {total_steps}')\n",
    "print(f'Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7025c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch} Training')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss = total_loss / (batch_idx + 1)\n",
    "        progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}'})\n",
    "        \n",
    "        if hasattr(torch, 'mps') and torch.backends.mps.is_available():\n",
    "            if batch_idx % 10 == 0:\n",
    "                torch.mps.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97c81d9c-3915-4824-b5bd-7a9ecd40e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc='Validating')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            progress_bar.set_postfix({'Val Loss': f'{outputs.loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87867339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f13fcd9e174463ad47f3f3381d9e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4d981427eb4d57a8513c98d7af5a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.4627\n",
      "Validation Loss: 3.1086\n",
      "Epoch Duration: 0.36 minutes\n",
      "New best model - saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939dbff117e745938a6700dc69f6bdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203d5920df50481dbcbd5a44fff56089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.5052\n",
      "Validation Loss: 2.9424\n",
      "Epoch Duration: 0.34 minutes\n",
      "New best model - saving...\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a363a33206438b8e5adaa09fc39d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4242f03ec643efaf7a88c155f47824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.2148\n",
      "Validation Loss: 2.8462\n",
      "Epoch Duration: 0.33 minutes\n",
      "New best model - saving...\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('training_logs', exist_ok=True)\n",
    "\n",
    "print('Training started...\\n')\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "training_history = {'train_loss': [], 'val_loss': [], 'epoch_times': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f'\\nEpoch {epoch}/{EPOCHS}')\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    \n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    epoch_time = time.time() - start_time\n",
    "    training_history['epoch_times'].append(epoch_time)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "    print(f'Epoch Duration: {epoch_time/60:.2f} minutes')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print('New best model - saving...')\n",
    "        model.save_pretrained('models/appetite_bart_best')\n",
    "        tokenizer.save_pretrained('models/appetite_bart_best')\n",
    "        \n",
    "        model_info = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'training_time': sum(training_history['epoch_times']),\n",
    "            'date_saved': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        with open('models/appetite_bart_best/training_info.json', 'w') as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "\n",
    "with open('training_logs/training_history.json', 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "\n",
    "print('\\nTraining complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d466a5c",
   "metadata": {},
   "source": [
    "## 6. Load Fine-tuned Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bff1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model loaded successfully!\n",
      "Best epoch: 3\n",
      "Validation loss: 2.8462\n",
      "Training time: 1.0 minutes\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = BartForConditionalGeneration.from_pretrained('models/appetite_bart_best')\n",
    "finetuned_tokenizer = BartTokenizer.from_pretrained('models/appetite_bart_best')\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "finetuned_model.eval()\n",
    "\n",
    "print('Fine-tuned model loaded successfully!')\n",
    "\n",
    "try:\n",
    "    with open('models/appetite_bart_best/training_info.json', 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    print(f'Best epoch: {training_info[\"epoch\"]}')\n",
    "    print(f'Validation loss: {training_info[\"val_loss\"]:.4f}')\n",
    "    print(f'Training time: {training_info[\"training_time\"]/60:.1f} minutes')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4d0cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fine-tuned model:\n",
      "\n",
      "Test 1\n",
      "Input: Generate a Healthy recipe using: chicken breast, broccoli, olive oil, garlic, lemon\n",
      "Generated Recipe: Recipe: 1. Instructions: preheat oven to 350°f. season chicken breast with salt and pepper. add broccoli, broccoli, and broccoli to a large bowl. season with garlic and season with salt, pepper, and garlic. cook until tender, about 2 minutes. remove chicken breast from the breast and let cool slightly. stir in broccoli and broccoli. let cool, stirring occasionally, until the broccoli is tender and tender. add chicken breast and broccoli and cook until browned, about 3 minutes. add the broccoli and chicken breast to the chicken breast, then season with olive oil. serve chicken breast in a small bowl over medium-high heat, stirring often, until cooked through, about 10 minutes. transfer to a plate and\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test 2\n",
      "Input: Generate a Quick Meals recipe using: pasta, tomato sauce, basil, mozzarella cheese\n",
      "Generated Recipe: Recipe: 1125. Instructions: preheat oven to 400°f. season with salt and pepper. add mozzarella cheese, basil, and basil to the pasta. toss to coat. add the basil and basil. cover with tomato sauce and season with basil. serve in a large saucepan over medium-high heat, stirring occasionally, until the sauce is golden brown, about 3 minutes. serve on a large plate. toss with remaining basil and tomato sauce. serve with basil and toss with basil, tomato sauce, salt, and pepper, tossing occasionally. add basil and pepper to the saucepan. serve. garnish with 1/2 cup of basil and sprinkle with salt, pepper, and 1/4 cup of mo\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test 3\n",
      "Input: Generate an Indulgent recipe using: chocolate, cream, butter, vanilla, eggs\n",
      "Generated Recipe: Recipe: Instructions: preheat oven to 350°f. whisk together chocolate, butter, vanilla, and eggs in a large bowl. whisk until smooth, about 2 minutes. add eggs, sugar, and vanilla. stir until smooth. whisk in vanilla, eggs, and chocolate mixture. add vanilla and eggs and whisk until combined. pour in the chocolate mixture, stirring often, until smooth and smooth. let cool, about 5 minutes. stir in eggs and vanilla, stirring occasionally, until the mixture is smooth. add milk and vanilla and stir to combine. add chocolate and vanilla mixture and stir until blended. whisk again, stirring constantly, until combined, about 10 minutes. transfer chocolate mixture to a bowl and pour over the remaining chocolate mixture\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_recipes = [\n",
    "    \"Generate a Healthy recipe using: chicken breast, broccoli, olive oil, garlic, lemon\",\n",
    "    \"Generate a Quick Meals recipe using: pasta, tomato sauce, basil, mozzarella cheese\",\n",
    "    \"Generate an Indulgent recipe using: chocolate, cream, butter, vanilla, eggs\",\n",
    "]\n",
    "\n",
    "print('Testing fine-tuned model:\\n')\n",
    "\n",
    "for i, test_input in enumerate(test_recipes, 1):\n",
    "    print(f'Test {i}')\n",
    "    print(f'Input: {test_input}')\n",
    "    \n",
    "    inputs = finetuned_tokenizer(test_input, return_tensors='pt', max_length=128, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = finetuned_model.generate(\n",
    "            **inputs,\n",
    "            max_length=150,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=3,\n",
    "            early_stopping=True,\n",
    "            temperature=0.8,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    ai_recipe = finetuned_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    print(f'Generated Recipe: {ai_recipe}')\n",
    "    print('-' * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551acded",
   "metadata": {},
   "source": [
    "## 7. Evaluation with ROUGE Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec935bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 10 samples...\n",
      "\n",
      "Evaluation Results:\n",
      "ROUGE-1: 0.3340\n",
      "ROUGE-2: 0.0986\n",
      "ROUGE-L: 0.1897\n",
      "\n",
      "Overall ROUGE: 0.2074\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def simple_evaluation(model, tokenizer, val_df, device, num_samples=10):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    model.eval()\n",
    "    sample_indices = np.random.choice(len(val_df), min(num_samples, len(val_df)), replace=False)\n",
    "    \n",
    "    print(f'Evaluating on {len(sample_indices)} samples...\\n')\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        input_text = val_df.iloc[idx]['input_text']\n",
    "        reference_text = val_df.iloc[idx]['target_text']\n",
    "        \n",
    "        inputs = tokenizer(input_text, return_tensors='pt', max_length=128, truncation=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_length=150, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        try:\n",
    "            scores = scorer.score(reference_text, prediction)\n",
    "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    results = {\n",
    "        'ROUGE-1': np.mean(rouge1_scores),\n",
    "        'ROUGE-2': np.mean(rouge2_scores),\n",
    "        'ROUGE-L': np.mean(rougeL_scores)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "eval_results = simple_evaluation(finetuned_model, finetuned_tokenizer, val_df, device, num_samples=10)\n",
    "\n",
    "print('Evaluation Results:')\n",
    "print(f'ROUGE-1: {eval_results[\"ROUGE-1\"]:.4f}')\n",
    "print(f'ROUGE-2: {eval_results[\"ROUGE-2\"]:.4f}')\n",
    "print(f'ROUGE-L: {eval_results[\"ROUGE-L\"]:.4f}')\n",
    "\n",
    "overall_rouge = (eval_results['ROUGE-1'] + eval_results['ROUGE-2'] + eval_results['ROUGE-L']) / 3\n",
    "print(f'\\nOverall ROUGE: {overall_rouge:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f7e68",
   "metadata": {},
   "source": [
    "## 8. Safety Features and Model Card\n",
    "\n",
    "### Allergen Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "954f8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "ALLERGENS = ['peanut', 'milk', 'egg', 'soy', 'fish', 'shellfish', 'wheat', 'gluten', 'sesame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cee1c89-6563-4282-92e2-1e6de64151f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_allergens(text):\n",
    "    found = [a for a in ALLERGENS if re.search(rf'\\b{a}', text.lower())]\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "285b6dab-5cae-47e5-917b-99bd5475c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_check(recipe_text):\n",
    "    allergens = detect_allergens(recipe_text)\n",
    "    if allergens:\n",
    "        print(f'Warning: Contains allergens: {allergens}')\n",
    "    \n",
    "    if any(bad in recipe_text.lower() for bad in ['kill', 'poison', 'suicide']):\n",
    "        print('Unsafe content detected! Review required.')\n",
    "    \n",
    "    return allergens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9f32683-7e55-4158-bc50-06d0ef111642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Contains allergens: ['peanut', 'egg']\n",
      "Detected allergens: ['peanut', 'egg']\n"
     ]
    }
   ],
   "source": [
    "sample_recipe = \"Recipe: Peanut Butter Cookies. Instructions: Mix peanut butter, eggs, sugar...\"\n",
    "allergens = safety_check(sample_recipe)\n",
    "print(f'Detected allergens: {allergens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c0849",
   "metadata": {},
   "source": [
    "### Prediction Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2fce233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged prediction for monitoring.\n"
     ]
    }
   ],
   "source": [
    "def log_prediction(input_text, output_text, allergens=None):\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    entry = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'input': input_text,\n",
    "        'output': output_text,\n",
    "        'allergens': allergens or []\n",
    "    }\n",
    "    \n",
    "    with open('logs/predictions.jsonl', 'a') as f:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "    print('Logged prediction for monitoring.')\n",
    "\n",
    "log_prediction(\n",
    "    \"Generate a Healthy recipe using: chicken, broccoli\",\n",
    "    \"Recipe: Grilled Chicken with Broccoli...\",\n",
    "    allergens=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db76a7d",
   "metadata": {},
   "source": [
    "### Model Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84a23eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Card created: MODEL_CARD.md\n"
     ]
    }
   ],
   "source": [
    "def create_model_card(name='AppetIte-BART', version='v1.0'):\n",
    "    card = f\"\"\"# Model Card: {name}\n",
    "\n",
    "## Model Information\n",
    "- **Version:** {version}\n",
    "- **Base Model:** facebook/bart-base\n",
    "- **Purpose:** Generate recipes from ingredients\n",
    "- **Training Data:** Curated AppetIteDataset.csv (100 samples)\n",
    "\n",
    "## Intended Use\n",
    "- Input: List of ingredients and desired category (Healthy, Quick Meals, Indulgent, Family-Friendly)\n",
    "- Output: Recipe name and cooking instructions\n",
    "\n",
    "## Limitations & Risks\n",
    "- May generate recipes containing common allergens\n",
    "- Limited to patterns seen in training data\n",
    "- Not a substitute for professional dietary advice\n",
    "\n",
    "## Mitigation Strategies\n",
    "- Allergen detection filter implemented\n",
    "- User feedback collection for improvement\n",
    "- Manual review for edge cases\n",
    "\n",
    "## Contact\n",
    "Project Maintainer: Sharath\n",
    "\n",
    "## License\n",
    "Educational use only\n",
    "\"\"\"\n",
    "    \n",
    "    with open('MODEL_CARD.md', 'w') as f:\n",
    "        f.write(card)\n",
    "    print('Model Card created: MODEL_CARD.md')\n",
    "\n",
    "create_model_card()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d20256",
   "metadata": {},
   "source": [
    "## 9. Complete Pipeline Function\n",
    "\n",
    "This function combines everything for easy recipe generation with safety checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f23f469e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPLETE RECIPE GENERATION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Logged prediction for monitoring.\n",
      "Input: chicken, rice, vegetables\n",
      "Category: Healthy\n",
      "Generated Recipe: Recipe: 1. Instructions: preheat oven to 350°f. add chicken, rice, and rice to a large bowl and stir until cooked through. add rice, chicken, and chicken to the bowl. stir until rice is tender, about 1/2 cup. cover with foil and let cool, stirring occasionally, until the chicken is tender. transfer to a plate and serve with rice and chicken. refrigerate until ready to serve. transfer chicken to a bowl and serve on a rimmed baking sheet. place chicken on a baking sheet and cover with plastic wrap. serve chicken and rice in a small bowl over medium-high heat. let cool slightly, stirring often, until chicken is golden brown, about 2 to 3 minutes.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Logged prediction for monitoring.\n",
      "Input: pasta, cheese, tomato sauce\n",
      "Category: Quick Meals\n",
      "Generated Recipe: Recipe: 1. Instructions: preheat oven to 350°f. add pasta, cheese, and tomato sauce to a large bowl and mix until smooth. add cheese, tomato sauce, and salt. season with salt and pepper and season with pepper and pepper. serve on a large plate. refrigerate until cheese is tender, about 15 minutes. serve in a small bowl over medium-high heat. cover with plastic wrap and refrigerate for at least 30 minutes. add the pasta and cheese mixture to the pasta mixture. toss to coat with salt, pepper, salt, and pepper, stirring often. serve with cheese and pepper in a large saucepan over medium heat, stirring occasionally, until the pasta is golden brown. serve immediately.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Logged prediction for monitoring.\n",
      "Input: chocolate, cream, strawberries\n",
      "Category: Indulgent\n",
      "Generated Recipe: Recipe: 1. Instructions: preheat oven to 350°f. whisk together chocolate, strawberries, vanilla, and vanilla until smooth, about 2 minutes. add strawberries, cream, and strawberries to a bowl and mix until smooth. transfer to a large bowl. cover with plastic wrap and refrigerate until firm, about 10 minutes. let cool, stirring occasionally, to remove excess. stir in strawberries and vanilla. add chocolate and vanilla, stirring often, and stir until smooth and smooth. add the strawberries and strawberries. pour in the chocolate mixture. stir until the strawberries are golden brown, about 3 minutes. transfer the strawberries to the bowl and toss in the remaining strawberries. whisk in the cream and vanilla mixture. pour the strawberries over the\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_recipe_with_safety(ingredients, category='Healthy', model=None, tokenizer=None):\n",
    "    if model is None:\n",
    "        model = finetuned_model\n",
    "    if tokenizer is None:\n",
    "        tokenizer = finetuned_tokenizer\n",
    "    \n",
    "    input_text = f\"Generate a {category} recipe using: {ingredients}\"\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors='pt', max_length=128, truncation=True).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=150,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=3,\n",
    "            early_stopping=True,\n",
    "            temperature=0.8,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    recipe_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    allergens = detect_allergens(recipe_text)\n",
    "    \n",
    "    log_prediction(input_text, recipe_text, allergens)\n",
    "    \n",
    "    result = {\n",
    "        'input': input_text,\n",
    "        'recipe': recipe_text,\n",
    "        'category': category,\n",
    "        'allergens': allergens,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('COMPLETE RECIPE GENERATION PIPELINE')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "test_cases = [\n",
    "    ('chicken, rice, vegetables', 'Healthy'),\n",
    "    ('pasta, cheese, tomato sauce', 'Quick Meals'),\n",
    "    ('chocolate, cream, strawberries', 'Indulgent')\n",
    "]\n",
    "\n",
    "for ingredients, category in test_cases:\n",
    "    result = generate_recipe_with_safety(ingredients, category)\n",
    "    \n",
    "    print(f\"Input: {ingredients}\")\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Generated Recipe: {result['recipe']}\")\n",
    "    if result['allergens']:\n",
    "        print(f\"Allergens: {result['allergens']}\")\n",
    "    print('-' * 80)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
